{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict next year results using previous year model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "import data_loader\n",
    "import model_builder\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/h6x/git_projects/overdose_modeling/SEResNet_15_channels/models/trained_models/se_restnet_2018_80_data.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup target device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model instance\n",
    "CONFIG_NAME = 50\n",
    "model = model_builder.SEResNet(CONFIG_NAME).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model state dictionary\n",
    "checkpoint = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved model weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEResNet(\n",
       "  (blocks): ModuleList(\n",
       "    (0): ResNetBlock(\n",
       "      (p): ConvBlock(\n",
       "        (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c1): ConvBlock(\n",
       "        (c): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c2): ConvBlock(\n",
       "        (c): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c3): ConvBlock(\n",
       "        (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (seblock): SeBlock(\n",
       "        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (fc1): Linear(in_features=256, out_features=16, bias=False)\n",
       "        (fc2): Linear(in_features=16, out_features=256, bias=False)\n",
       "        (relu): ReLU()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (1-2): 2 x ResNetBlock(\n",
       "      (c1): ConvBlock(\n",
       "        (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c2): ConvBlock(\n",
       "        (c): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c3): ConvBlock(\n",
       "        (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (seblock): SeBlock(\n",
       "        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (fc1): Linear(in_features=256, out_features=16, bias=False)\n",
       "        (fc2): Linear(in_features=16, out_features=256, bias=False)\n",
       "        (relu): ReLU()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (3): ResNetBlock(\n",
       "      (p): ConvBlock(\n",
       "        (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c1): ConvBlock(\n",
       "        (c): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c2): ConvBlock(\n",
       "        (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c3): ConvBlock(\n",
       "        (c): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (seblock): SeBlock(\n",
       "        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (fc1): Linear(in_features=512, out_features=32, bias=False)\n",
       "        (fc2): Linear(in_features=32, out_features=512, bias=False)\n",
       "        (relu): ReLU()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (4-6): 3 x ResNetBlock(\n",
       "      (c1): ConvBlock(\n",
       "        (c): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c2): ConvBlock(\n",
       "        (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c3): ConvBlock(\n",
       "        (c): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (seblock): SeBlock(\n",
       "        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (fc1): Linear(in_features=512, out_features=32, bias=False)\n",
       "        (fc2): Linear(in_features=32, out_features=512, bias=False)\n",
       "        (relu): ReLU()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (7): ResNetBlock(\n",
       "      (p): ConvBlock(\n",
       "        (c): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c1): ConvBlock(\n",
       "        (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c2): ConvBlock(\n",
       "        (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c3): ConvBlock(\n",
       "        (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (seblock): SeBlock(\n",
       "        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (fc1): Linear(in_features=1024, out_features=64, bias=False)\n",
       "        (fc2): Linear(in_features=64, out_features=1024, bias=False)\n",
       "        (relu): ReLU()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (8-12): 5 x ResNetBlock(\n",
       "      (c1): ConvBlock(\n",
       "        (c): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c2): ConvBlock(\n",
       "        (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c3): ConvBlock(\n",
       "        (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (seblock): SeBlock(\n",
       "        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (fc1): Linear(in_features=1024, out_features=64, bias=False)\n",
       "        (fc2): Linear(in_features=64, out_features=1024, bias=False)\n",
       "        (relu): ReLU()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (13): ResNetBlock(\n",
       "      (p): ConvBlock(\n",
       "        (c): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c1): ConvBlock(\n",
       "        (c): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c2): ConvBlock(\n",
       "        (c): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c3): ConvBlock(\n",
       "        (c): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (seblock): SeBlock(\n",
       "        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (fc1): Linear(in_features=2048, out_features=128, bias=False)\n",
       "        (fc2): Linear(in_features=128, out_features=2048, bias=False)\n",
       "        (relu): ReLU()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (14-15): 2 x ResNetBlock(\n",
       "      (c1): ConvBlock(\n",
       "        (c): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c2): ConvBlock(\n",
       "        (c): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (c3): ConvBlock(\n",
       "        (c): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (seblock): SeBlock(\n",
       "        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (fc1): Linear(in_features=2048, out_features=128, bias=False)\n",
       "        (fc2): Linear(in_features=128, out_features=2048, bias=False)\n",
       "        (relu): ReLU()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv1): ConvBlock(\n",
       "    (c): Conv2d(15, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transforms for the new dataset\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories for the new dataset\n",
    "\n",
    "# change 80.90,95 in both paths depending on the model used\n",
    "\n",
    "# next year - 2020\n",
    "# new_root_dir = \"/home/h6x/git_projects/data_processing/processed_data/adjacency_pers_images_npy_county/2020/experimet_3/npy_combined\"\n",
    "# new_annotation_file_path = \"/home/h6x/git_projects/data_processing/processed_data/adjacency_pers_images_npy_county/2020/experimet_3/annotations_2020_npy_2_classes_only_h0h1_80_percentile_all_data.csv\"\n",
    "\n",
    "#same year - 2018\n",
    "new_root_dir = \"/home/h6x/git_projects/data_processing/processed_data/adjacency_pers_images_npy_county/experimet_3/npy_combined\"\n",
    "new_annotation_file_path = \"/home/h6x/git_projects/data_processing/processed_data/adjacency_pers_images_npy_county/experimet_3/annotations_2018_npy_2_classes_only_h0h1_80_percentile_all_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(new_annotation_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OD_class\n",
      "0    2154\n",
      "1     586\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get count of each class on the \"OD_class\" column\n",
    "print(all_data['OD_class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "data_set = data_loader.data_loader_persistence_img(annotation_file_path=new_annotation_file_path, root_dir=new_root_dir, transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names\n",
    "class_names = data_set.get_class_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "NUM_WORKERS = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn images into data loaders\n",
    "new_dataloader = DataLoader(\n",
    "      data_set,\n",
    "      batch_size=BATCH_SIZE,\n",
    "      shuffle=False,\n",
    "      num_workers=NUM_WORKERS,\n",
    "      pin_memory=True,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_evaluate(model, dataloader, device):\n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return np.array(all_labels), np.array(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/h6x/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and collect the ground truth labels\n",
    "y_true, y_pred = predict_and_evaluate(model, new_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 - TPR: 0.87, FPR: 0.50, FNR: 0.13\n",
      "Class 1 - TPR: 0.50, FPR: 0.13, FNR: 0.50\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate TPR and FPR for each class\n",
    "def calculate_tpr_fpr(conf_matrix):\n",
    "    num_classes = conf_matrix.shape[0]\n",
    "    TPR = np.zeros(num_classes)\n",
    "    FPR = np.zeros(num_classes)\n",
    "    FNR = np.zeros(num_classes)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        TP = conf_matrix[i, i]\n",
    "        FN = np.sum(conf_matrix[i, :]) - TP\n",
    "        FP = np.sum(conf_matrix[:, i]) - TP\n",
    "        TN = np.sum(conf_matrix) - (TP + FN + FP)\n",
    "        \n",
    "        TPR[i] = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "        FPR[i] = FP / (FP + TN) if (FP + TN) != 0 else 0\n",
    "        FNR[i] = FN / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    \n",
    "    return TPR, FPR, FNR\n",
    "\n",
    "# Calculate TPR and FPR\n",
    "TPR, FPR, FNR = calculate_tpr_fpr(conf_matrix)\n",
    "\n",
    "# Print TPR and FPR for each class\n",
    "for idx, class_name in enumerate(class_names):\n",
    "    print(f\"Class {class_name} - TPR: {TPR[idx]:.2f}, FPR: {FPR[idx]:.2f}, FNR: {FNR[idx]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(conf_matrix, class_names):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    # plt.savefig('/home/h6x/git_projects/overdose_modeling/SEResNet_15_channels/plots/confusion_matrix_95_percentile_2020_prediction.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0YAAAJuCAYAAACUrBL3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuBUlEQVR4nO3debRXZaH/8c+X6TAoKCIo5gSmghPT1Qumoqg3NYubpamlCDjXdc7I6zygZCqigBNiaA6VctWMHBBzwETCMrWsBIebpKChgALC+f3hz3M9AQp64ADP67UWa/nd+9l7P/us1fr2Pns4lerq6uoAAAAUrEF9TwAAAKC+CSMAAKB4wggAACieMAIAAIonjAAAgOIJIwAAoHjCCAAAKJ4wAgAAiieMAACA4gkjgDXIH/7whxxxxBHZfPPN07Rp06y11lrp1q1bhgwZkrfeemuFHnvKlCnZbbfd0qpVq1QqlVxxxRV1foxKpZJzzjmnzvf7aUaPHp1KpZJKpZIJEyYstr66ujpbbLFFKpVKevfu/ZmOMXz48IwePXq5tpkwYcJS5wTA8mlU3xMAoG5cd911Oe6447LVVlvltNNOS+fOnbNgwYI8/fTTGTlyZCZOnJi77rprhR2/f//+mTNnTm677basu+662Wyzzer8GBMnTswXvvCFOt/vslp77bVzww03LBY/jzzySP72t79l7bXX/sz7Hj58eNq0aZN+/fot8zbdunXLxIkT07lz5898XAA+JIwA1gATJ07Msccem7322itjx45NVVVVzbq99torp5xySsaNG7dC5/DHP/4xRx55ZPbZZ58Vdox///d/X2H7XhYHHXRQbrnlllx99dVp2bJlzfIbbrghPXv2zDvvvLNS5rFgwYJUKpW0bNmy3n8mAGsKt9IBrAEuuuiiVCqVXHvttbWi6CNNmjTJV7/61ZrPixYtypAhQ7L11lunqqoqbdu2zWGHHZbXXnut1na9e/fOtttum0mTJmWXXXZJ8+bN06FDh1x88cVZtGhRkv+7zeyDDz7IiBEjam45S5Jzzjmn5r8/7qNtpk2bVrNs/Pjx6d27d9Zbb700a9Ysm2yySQ444IDMnTu3ZsySbqX74x//mK997WtZd91107Rp03Tp0iU33XRTrTEf3XJ266235owzzkj79u3TsmXL7Lnnnvnzn/+8bD/kJAcffHCS5NZbb61ZNmvWrPziF79I//79l7jNueeem5122imtW7dOy5Yt061bt9xwww2prq6uGbPZZpvlueeeyyOPPFLz8/voittHcx8zZkxOOeWUbLTRRqmqqspf//rXxW6lmzFjRjbeeOP06tUrCxYsqNn/888/nxYtWuQ73/nOMp8rQGmEEcBqbuHChRk/fny6d++ejTfeeJm2OfbYY3P66adnr732yt13353zzz8/48aNS69evTJjxoxaY6dPn55DDz003/72t3P33Xdnn332yaBBg3LzzTcnSfbbb79MnDgxSfKNb3wjEydOrPm8rKZNm5b99tsvTZo0yahRozJu3LhcfPHFadGiRebPn7/U7f785z+nV69eee6553LllVfmzjvvTOfOndOvX78MGTJksfE//OEP8/LLL+f666/Ptddem7/85S/Zf//9s3DhwmWaZ8uWLfONb3wjo0aNqll26623pkGDBjnooIOWem5HH3107rjjjtx55535+te/nu9973s5//zza8bcdddd6dChQ7p27Vrz8/vX2x4HDRqUV155JSNHjsw999yTtm3bLnasNm3a5LbbbsukSZNy+umnJ0nmzp2bb37zm9lkk00ycuTIZTpPgBK5lQ5gNTdjxozMnTs3m2+++TKN/9Of/pRrr702xx13XIYNG1azvGvXrtlpp51y+eWX58ILL6xZPnPmzNx3333ZcccdkyR77rlnJkyYkJ/+9Kc57LDDsv7662f99ddPkrRr1+4z3do1efLkvP/++/nRj36UHXbYoWb5IYcc8onbnXPOOZk/f34efvjhmijcd999889//jPnnntujj766LRq1apmfOfOnWuCLkkaNmyYAw88MJMmTVrmeffv3z+77757nnvuuWyzzTYZNWpUvvnNby71+aIbb7yx5r8XLVqU3r17p7q6OkOHDs2ZZ56ZSqWSrl27plmzZp94a1zHjh3zs5/97FPnt/POO+fCCy/M6aefnl133TVjx47N1KlT89vf/jYtWrRYpnMEKJErRgCFefjhh5NksYf8d9xxx3Tq1CkPPfRQreUbbLBBTRR9ZPvtt8/LL79cZ3Pq0qVLmjRpkqOOOio33XRTXnrppWXabvz48enTp89iV8r69euXuXPnLnbl6uO3EyYfnkeS5TqX3XbbLR07dsyoUaPy7LPPZtKkSUu9je6jOe65555p1apVGjZsmMaNG+ess87KzJkz88YbbyzzcQ844IBlHnvaaadlv/32y8EHH5ybbropw4YNy3bbbbfM2wOUSBgBrObatGmT5s2bZ+rUqcs0fubMmUmSDTfccLF17du3r1n/kfXWW2+xcVVVVXnvvfc+w2yXrGPHjnnwwQfTtm3bHH/88enYsWM6duyYoUOHfuJ2M2fOXOp5fLT+4/71XD56Hmt5zqVSqeSII47IzTffnJEjR2bLLbfMLrvsssSxTz31VPbee+8kH7418PHHH8+kSZNyxhlnLPdxl3SenzTHfv365f33388GG2zg2SKAZSCMAFZzDRs2TJ8+fTJ58uTFXp6wJB/Fweuvv77Yur///e9p06ZNnc2tadOmSZJ58+bVWv6vzzElyS677JJ77rkns2bNypNPPpmePXvmxBNPzG233bbU/a+33npLPY8kdXouH9evX7/MmDEjI0eOzBFHHLHUcbfddlsaN26ce++9NwceeGB69eqVHj16fKZjLuklFkvz+uuv5/jjj0+XLl0yc+bMnHrqqZ/pmAAlEUYAa4BBgwaluro6Rx555BJfVrBgwYLcc889SZI99tgjSWo9a5MkkyZNygsvvJA+ffrU2bw+erPaH/7wh1rLP5rLkjRs2DA77bRTrr766iTJ7373u6WO7dOnT8aPH18TQh/5yU9+kubNm6+wV1lvtNFGOe2007L//vvn8MMPX+q4SqWSRo0apWHDhjXL3nvvvYwZM2axsXV1FW7hwoU5+OCDU6lU8qtf/SqDBw/OsGHDcuedd37ufQOsybx8AWAN0LNnz4wYMSLHHXdcunfvnmOPPTbbbLNNFixYkClTpuTaa6/Ntttum/333z9bbbVVjjrqqAwbNiwNGjTIPvvsk2nTpuXMM8/MxhtvnJNOOqnO5rXvvvumdevWGTBgQM4777w0atQoo0ePzquvvlpr3MiRIzN+/Pjst99+2WSTTfL+++/XvPltzz33XOr+zz777Nx7773Zfffdc9ZZZ6V169a55ZZb8stf/jJDhgyp9eKFunbxxRd/6pj99tsvl112WQ455JAcddRRmTlzZi699NIlvlJ9u+22y2233Zbbb789HTp0SNOmTT/Tc0Fnn312Hn300dx///3ZYIMNcsopp+SRRx7JgAED0rVr12V+SQdAaYQRwBriyCOPzI477pjLL788l1xySaZPn57GjRtnyy23zCGHHJLvfve7NWNHjBiRjh075oYbbsjVV1+dVq1a5ctf/nIGDx68xGeKPquWLVtm3LhxOfHEE/Ptb38766yzTgYOHJh99tknAwcOrBnXpUuX3H///Tn77LMzffr0rLXWWtl2221z99131zyjsyRbbbVVnnjiifzwhz/M8ccfn/feey+dOnXKjTfeuNjLJerDHnvskVGjRuWSSy7J/vvvn4022ihHHnlk2rZtmwEDBtQae+655+b111/PkUcemXfffTebbrpprb/ztCweeOCBDB48OGeeeWatK3+jR49O165dc9BBB+Wxxx5LkyZN6uL0ANYoleqP/4U5AACAAnnGCAAAKJ4wAgAAiieMAACA4gkjAACgeMIIAAAonjACAACKJ4wAAIDirZF/4LVZ1+9++iAA1nhvT7qqvqcAQD1ruozF44oRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPEa1fcEgCXbuVvHnHTYnunWeZNsuH6rHHjStblnwh9q1rdo1iQX/NfXsv/u26d1qxZ5+e9vZfhtE3Ldzx5LkmyyYev8+b7zlrjvQ0+7IXc+OCVJ8qdfnptN269Xa/2lN96fM6+8ewWdGQCf1Q3XXZOHHrg/U6e+lKqmTdOlS9ecePKp2WzzDjVjdthmqyVue9Ipp6Vf/4FJkldfeSU/vvSSPPO7yZk/f352/tIu+cEPz8x6bdqslPOAVZEwglVUi2ZVefbF/82Yu5/MbT8+crH1Q049ILv12DJHnPGTvPz3mdmzZ6cMHXRgXn9zVu6d8Gxe+8fb2WzPQbW26X/Azjn58L3y68efq7X83OH35sY7H6/5PHvuvBVzUgB8Lk9PeioHHXxottluuyz8YGGGXXl5jjlyQO68+5dp3rx5kuShCY/V2uaxx36Tc848I3vu9R9Jkrlz5+aYo/pny622znWjbkqSXD1saL53/DG5+dY70qCBG4ookzCCVdT9jz+f+x9/fqnrd9p+89x872/z6OS/JElG3fl4Bhywc7p13iT3Tng2ixZV5x8z3621zVd33yE/v39y5rw3v9by2XPeX2wsAKueEdfeUOvzeRcMzu679MwLzz+X7j3+LUnSZv31a42ZMP6h/NuOO+ULG2+cJHlmyu/y9//939z+87FZa621avazS68d89Rvn8y/9+y1Es4EVj1+JQCrqSeeeSlf2W27tF+/VZJk1x5fzBc3bZsHn3hhieO7dto4XbbeODeNnbjYupP77ZXXHr4kT972g3x/wH+kcaOGK3TuANSN2e9++Eutlq1aLXH9zBkz8uhvHsl/fv0bNcvmz5+fSqWSJk2a1CxrUlWVBg0aZMrvJq/YCcMqrF6vGL322msZMWJEnnjiiUyfPj2VSiXt2rVLr169cswxx2Tj//+bjU8yb968zJtX+7af6kULU2ng/9ixZjvlkp9l+FmH5G/3X5gFCxZmUfWiHHveT/PEMy8tcfzhfXvmhZdez5O/n1pr+dU/nZApf3o1/3xnbnpsu2nO+95Xs9lG6+W48366Mk4DgM+ouro6lw4ZnK7duueLX9xyiWPu/p+70rx5i/TZa++aZdvv0CXNmjXLFT/+Ub534smprq7OFZddmkWLFuXNN99cWdOHVU69XTF67LHH0qlTp9x1113ZYYcdcthhh+Xb3/52dthhh4wdOzbbbLNNHn/88U/dz+DBg9OqVata/z74h992sOY7/uDe2XG7zXLACSPT69BL8oPL7srQQQdl950Wf+i2aVXjHLRPjyVeLRp2y8N5bPJf88e//D2j75qY/7rw9hzxn73SulWLlXEaAHxGgy84L3958cVc8qPLljpm7F2/yL5f2T9VVVU1y1q3bp0fXTY0jzzycHr+W9d86d97ZPbsd9Op8zZp6PkiClZvV4xOOumkDBw4MJdffvlS15944omZNGnSJ+5n0KBBOfnkk2sta7vL6XU2T1gVNa1qnHO/t38OOvm6jHvswxcp/PEvf8/2W30hJ36nTx7+7Z9rjf/PPbukedMmueXepz5130/94cMrSh03bpO3Zs2p+8kD8LkNvvD8TJgwPqNuujntNthgiWN+N/npTJs6NUMuvWKxdb12/lJ+Oe7BvP32W2nYsFFatmyZPXbdORvt84UVPHNYddVbGP3xj3/MzTffvNT1Rx99dEaOHPmp+6mqqqr1W5AkbqNjjde4UcM0adwoi6qray1fuHBRGjSoLDa+X99e+eUjz2bG27M/dd87bP3hLazTZ7xTN5MFoM5UV1dn8IXnZ/xDD+SG0WPyhS8s/bGDu37x83TeZptstfXWSx2z7rqtkyS/fXJi3nprZnrvvkedzxlWF/UWRhtuuGGeeOKJbLXVkt+1P3HixGy44YYreVaw6mjRrEk6bvx/bxbabKP1sv2WG+Xtd+bm1elv5zdP/yUXndg3772/IK+8/lZ26b5FDv3Kjjn9sjtr7afDxm3ypW4d0/d7IxY7xk7bb54dt9ssj0x6MbNmv58e22ySIacekHsm/CGvTn97hZ8jAMvnovPPza/uuzdXDBueFs1bZMb/fyZorbXXTtOmTWvGzZ49O/ffPy6nnLbku2jG3vWLdOjQMeuu2zq///2UDBl8Ub59WL9afw8JSlNvYXTqqafmmGOOyeTJk7PXXnulXbt2qVQqmT59eh544IFcf/31ueKKK+prelDvunXeNPdff0LN5yGnHpAkGXP3kznq7Jtz2A9G5bzvfS2jLzo867ZsnldefyvnXH1vzR94/cjhX+uZv78xKw9O/NNix5g3f0G+sXe3/PDofVLVuFFeef2tjLrziVx20wMr9uQA+EzuuP3WJMmAft+ptfy8Cwbna//59ZrP4+77ZVJdnX32/coS9zNt6tRcefllmTVrVtpvtFEGHnVMvnN4vxU2b1gdVKqr/+VenJXo9ttvz+WXX57Jkydn4cKFSZKGDRume/fuOfnkk3PggQd+pv026/rdupwmAKuptyddVd9TAKCeNV3GS0H1GkYfWbBgQWbMmJEkadOmTRo3bvy59ieMAEiEEQDLHkb1+neMPtK4cWPPEwEAAPXGy+oBAIDiCSMAAKB4wggAACieMAIAAIonjAAAgOIJIwAAoHjCCAAAKJ4wAgAAiieMAACA4gkjAACgeMIIAAAonjACAACKJ4wAAIDiCSMAAKB4wggAACieMAIAAIonjAAAgOIJIwAAoHjCCAAAKJ4wAgAAiieMAACA4gkjAACgeMIIAAAonjACAACKJ4wAAIDiCSMAAKB4wggAACieMAIAAIonjAAAgOIJIwAAoHjCCAAAKJ4wAgAAiieMAACA4gkjAACgeMIIAAAonjACAACKJ4wAAIDiCSMAAKB4wggAACieMAIAAIonjAAAgOIJIwAAoHjCCAAAKJ4wAgAAiieMAACA4gkjAACgeMIIAAAonjACAACKJ4wAAIDiCSMAAKB4wggAACieMAIAAIonjAAAgOIJIwAAoHjCCAAAKJ4wAgAAiieMAACA4gkjAACgeMIIAAAonjACAACKJ4wAAIDiCSMAAKB4wggAACieMAIAAIonjAAAgOIJIwAAoHjCCAAAKJ4wAgAAiieMAACA4gkjAACgeMIIAAAonjACAACKJ4wAAIDiCSMAAKB4wggAACieMAIAAIonjAAAgOIJIwAAoHjCCAAAKJ4wAgAAiieMAACA4gkjAACgeMIIAAAonjACAACKJ4wAAIDiCSMAAKB4wggAACieMAIAAIonjAAAgOIJIwAAoHjCCAAAKJ4wAgAAiieMAACA4gkjAACgeMIIAAAonjACAACKJ4wAAIDiCSMAAKB4wggAACieMAIAAIonjAAAgOIJIwAAoHjCCAAAKJ4wAgAAiieMAACA4gkjAACgeMIIAAAonjACAACKJ4wAAIDiCSMAAKB4wggAACieMAIAAIonjAAAgOIJIwAAoHjCCAAAKN5nCqMxY8Zk5513Tvv27fPyyy8nSa644or8z//8T51ODgAAYGVY7jAaMWJETj755Oy777755z//mYULFyZJ1llnnVxxxRV1PT8AAIAVbrnDaNiwYbnuuutyxhlnpGHDhjXLe/TokWeffbZOJwcAALAyLHcYTZ06NV27dl1seVVVVebMmVMnkwIAAFiZljuMNt988zzzzDOLLf/Vr36Vzp0718WcAAAAVqpGy7vBaaedluOPPz7vv/9+qqur89RTT+XWW2/N4MGDc/3116+IOQIAAKxQyx1GRxxxRD744IN8//vfz9y5c3PIIYdko402ytChQ/Otb31rRcwRAABghapUV1dXf9aNZ8yYkUWLFqVt27Z1OafPrVnX79b3FABYBbw96ar6ngIA9azpMl4KWu4rRh/Xpk2bz7M5AADAKmG5w2jzzTdPpVJZ6vqXXnrpc00IAABgZVvuMDrxxBNrfV6wYEGmTJmScePG5bTTTqureQEAAKw0yx1GJ5xwwhKXX3311Xn66ac/94QAAABWts/18oWPe+mll9KlS5e88847dbG7z2Xugjo5JQAAYDXXvPHSHwP6uOX+A69L8/Of/zytW7euq90BAACsNMt9K13Xrl1rvXyhuro606dPz5tvvpnhw4fX6eQAAABWhuUOo759+9b63KBBg6y//vrp3bt3tt5667qaFwAAwEqzXGH0wQcfZLPNNst//Md/ZIMNNlhRcwIAAFiplvvlC82bN88LL7yQTTfddEXN6XPz8gUAACBZgS9f2GmnnTJlypTlnhAAAMCqarmfMTruuONyyimn5LXXXkv37t3TokWLWuu33377OpscAADAyrDMt9L1798/V1xxRdZZZ53Fd1KppLq6OpVKJQsXLqzrOS43t9IBAADJst9Kt8xh1LBhw7z++ut57733PnHcqvDskTACAACSZQ+jZb6V7qN+WhXCBwAAoC4t18sXPv6HXQEAANYUy3wrXYMGDdKqVatPjaO33nqrTib2ebiVDgAASFbArXRJcu6556ZVq1afaUIAAACrquW6YjR9+vS0bdt2Rc/pc3PFCAAASFbAH3j1fBEAALCmWuYwWsYLSwAAAKudZX7GaNGiRStyHgAAAPVmuV7XDQAAsCYSRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YwWrihuuuyaEHfSM779gte+zaKyf91/GZNvWlWmNmzpiRs874QfbafZf07NElxx89MC+/PK1m/axZ/8zFF52fvl/5cnr26JJ99tw9l1x0Qd59992VfDYAfBZ18V3wcdXV1Tn+mCPTddut8/BDD66EM4BVlzCC1cTvnp6Ugw4+JD/56e0Zce2oLPzggxx71MC8N3dukg+/3E464fi89tprueLK4bn1Z3dmw/btc8zA/jVj3nzjjbz5xhs56dTv54477865Fw7OE48/mnPPOqM+Tw2AZVQX3wUfd8uYm1KpVFb2acAqqVJdXV1d35Ooa3MXrHGnBIt566230mfXXrl+9Jh07/FveXna1PT9yj75+dh70nGLLyZJFi5cmD679sp/nXRqvv6Nby5xPw/8elzO+MFpeWLSlDRq1GhlngIAn9Pn+S7485/+lBOOPyY33/6z7NV7l1w29Krs3mfP+joVWGGaN162+HfFCFZTs2d/ePtbq1atkiTz589PkjRpUlUzpmHDhmncuEmemTJ5qft5991302KttUQRwGros34XvPfeexn0/VNy+hlnpk2b9VfijGHVtUqH0auvvpr+/ft/4ph58+blnXfeqfVv3rx5K2mGUD+qq6vz4yEXp2u37tnii1smSTbbvEM2bN8+w4ZelndmzcqCBfMz6vprM2PGm5nx5ptL3M8///l2rrtmRL7xzYNW5vQBqAOf57vgx0MGZ4cuXbP7Hn3qa/qwylmlw+itt97KTTfd9IljBg8enFatWtX6d+klg1fSDKF+XHzh+fnLi3/O4CE/rlnWuHHjXHr5lXl52rTstvNO6dmjayZPeio777JrGjRsuNg+Zs+enf867ph06NgxRx17/MqcPgB14LN+F0x4eHye+u1vc9oPBtXX1GGVVK/PGN19992fuP6ll17KKaeckoULFy51zLx58xa7QrSwQZNUVVUtZQtYvV180fmZ8NBDueGmm7PRF76wxDHvvvtuFixYkNatW+c7Bx+Yzttsm0H/fVbN+jlzZue4owamabNmufLqkf73ArCa+TzfBT+6+KLcesuYNGjwf78fX7hwYRo0aJCu3brn+tFjVtZpwEqxrM8Y1WsYNWjQIJVKJZ80hUql8olhtCRevsCaqLq6OpdcdH7GP/RgrrvxJ9l0080+dZuXX56Wr++/b64acW167vylJB9eKTru6AFp0rhJho24Ns2aNVvBMwegrtTFd8GMGW/mn2+/XWvMN//zqzntBz/Mbr33WGpowepqWcOoXp+23nDDDXP11Venb9++S1z/zDPPpHv37it3UrCKGnzBefnVfffm8iuvTosWLTJjxof3iq+11tpp2rRpkg/fMLfuuutmgw3b5y9/eTE/uvjC9N6jT00UfXilaEDef++9XDj0R5kzZ3bmzJmdJFl33dZpuIRb7gBYddTFd0GbNusv8YULG27YXhRRtHoNo+7du+d3v/vdUsPo064mQUl+dvutSZIjjzis1vJzL7goX+379STJm2++kR8PuTgzZ85Mm/XXz1e++rUcdcyxNWNfeO65PPuH3ydJvrrv3rX288tfP5j2G/lCBFiV1cV3AbBk9Xor3aOPPpo5c+bky1/+8hLXz5kzJ08//XR222235dqvW+kAAIBkNXnGaEURRgAAQOIPvAIAACwzYQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAABA8SrV1dXV9T0JoG7NmzcvgwcPzqBBg1JVVVXf0wGgnvg+gGUnjGAN9M4776RVq1aZNWtWWrZsWd/TAaCe+D6AZedWOgAAoHjCCAAAKJ4wAgAAiieMYA1UVVWVs88+24O2AIXzfQDLzssXAACA4rliBAAAFE8YAQAAxRNGAABA8YQRAABQPGEEa5jhw4dn8803T9OmTdO9e/c8+uij9T0lAFay3/zmN9l///3Tvn37VCqVjB07tr6nBKs8YQRrkNtvvz0nnnhizjjjjEyZMiW77LJL9tlnn7zyyiv1PTUAVqI5c+Zkhx12yFVXXVXfU4HVhtd1wxpkp512Srdu3TJixIiaZZ06dUrfvn0zePDgepwZAPWlUqnkrrvuSt++fet7KrBKc8UI1hDz58/P5MmTs/fee9davvfee+eJJ56op1kBAKwehBGsIWbMmJGFCxemXbt2tZa3a9cu06dPr6dZAQCsHoQRrGEqlUqtz9XV1YstAwCgNmEEa4g2bdqkYcOGi10deuONNxa7igQAQG3CCNYQTZo0Sffu3fPAAw/UWv7AAw+kV69e9TQrAIDVQ6P6ngBQd04++eR85zvfSY8ePdKzZ89ce+21eeWVV3LMMcfU99QAWIlmz56dv/71rzWfp06dmmeeeSatW7fOJptsUo8zg1WX13XDGmb48OEZMmRIXn/99Wy77ba5/PLLs+uuu9b3tABYiSZMmJDdd999seWHH354Ro8evfInBKsBYQQAABTPM0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFE8YAQAAxRNGAKz2zjnnnHTp0qXmc79+/dK3b9+VPo9p06alUqnkmWeeWenHBuDzEUYArDD9+vVLpVJJpVJJ48aN06FDh5x66qmZM2fOCj3u0KFDM3r06GUaK2YASJJG9T0BANZsX/7yl3PjjTdmwYIFefTRRzNw4MDMmTMnI0aMqDVuwYIFady4cZ0cs1WrVnWyHwDK4YoRACtUVVVVNthgg2y88cY55JBDcuihh2bs2LE1t7+NGjUqHTp0SFVVVaqrqzNr1qwcddRRadu2bVq2bJk99tgjv//972vt8+KLL067du2y9tprZ8CAAXn//fdrrf/XW+kWLVqUSy65JFtssUWqqqqyySab5MILL0ySbL755kmSrl27plKppHfv3jXb3XjjjenUqVOaNm2arbfeOsOHD691nKeeeipdu3ZN06ZN06NHj0yZMqUOf3IArEyuGAGwUjVr1iwLFixIkvz1r3/NHXfckV/84hdp2LBhkmS//fZL69atc99996VVq1a55ppr0qdPn7z44otp3bp17rjjjpx99tm5+uqrs8suu2TMmDG58sor06FDh6Uec9CgQbnuuuty+eWX50tf+lJef/31/OlPf0ryYdzsuOOOefDBB7PNNtukSZMmSZLrrrsuZ599dq666qp07do1U6ZMyZFHHpkWLVrk8MMPz5w5c/KVr3wle+yxR26++eZMnTo1J5xwwgr+6QGwoggjAFaap556Kj/96U/Tp0+fJMn8+fMzZsyYrL/++kmS8ePH59lnn80bb7yRqqqqJMmll16asWPH5uc//3mOOuqoXHHFFenfv38GDhyYJLngggvy4IMPLnbV6CPvvvtuhg4dmquuuiqHH354kqRjx4750pe+lCQ1x15vvfWywQYb1Gx3/vnn58c//nG+/vWvJ/nwytLzzz+fa665JocffnhuueWWLFy4MKNGjUrz5s2zzTbb5LXXXsuxxx5b1z82AFYCt9IBsELde++9WWuttdK0adP07Nkzu+66a4YNG5Yk2XTTTWvCJEkmT56c2bNnZ7311staa61V82/q1Kn529/+liR54YUX0rNnz1rH+NfPH/fCCy9k3rx5NTG2LN588828+uqrGTBgQK15XHDBBbXmscMOO6R58+bLNA8AVm2uGAGwQu2+++4ZMWJEGjdunPbt29d6wUKLFi1qjV20aFE23HDDTJgwYbH9rLPOOp/p+M2aNVvubRYtWpTkw9vpdtppp1rrPrrlr7q6+jPNB4BVkzACYIVq0aJFtthii2Ua261bt0yfPj2NGjXKZptttsQxnTp1ypNPPpnDDjusZtmTTz651H1+8YtfTLNmzfLQQw/V3H73cR89U7Rw4cKaZe3atctGG22Ul156KYceeugS99u5c+eMGTMm7733Xk18fdI8AFi1uZUOgFXGnnvumZ49e6Zv37759a9/nWnTpuWJJ57If//3f+fpp59OkpxwwgkZNWpURo0alRdffDFnn312nnvuuaXus2nTpjn99NPz/e9/Pz/5yU/yt7/9LU8++WRuuOGGJEnbtm3TrFmzjBs3Lv/4xz8ya9asJB/+0djBgwdn6NChefHFF/Pss8/mxhtvzGWXXZYkOeSQQ9KgQYMMGDAgzz//fO67775ceumlK/gnBMCKIowAWGVUKpXcd9992XXXXdO/f/9sueWW+da3vpVp06alXbt2SZKDDjooZ511Vk4//fR07949L7/88qe+8ODMM8/MKaeckrPOOiudOnXKQQcdlDfeeCNJ0qhRo1x55ZW55ppr0r59+3zta19LkgwcODDXX399Ro8ene222y677bZbRo8eXfN677XWWiv33HNPnn/++XTt2jVnnHFGLrnkkhX40wFgRapUu0kaAAAonCtGAABA8YQRAABQPGEEAAAUTxgBAADFE0YAAEDxhBEAAFA8YQQAABRPGAEAAMUTRgAAQPGEEQAAUDxhBAAAFO//AfzcAOy8yTaNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(conf_matrix, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
